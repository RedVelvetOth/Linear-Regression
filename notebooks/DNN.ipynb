{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('../data/train_data_stg.csv', delimiter='|')\n",
    "df_test = pd.read_csv('../data/test_data_stg.csv', delimiter='|')\n",
    "\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "df = df.drop(['rank'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = np.log(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 18:06:05.606711: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 18:06:05.609627: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 18:06:05.618466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 18:06:05.635555: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 18:06:05.635579: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-02 18:06:05.647665: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 18:06:06.663696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "X_train = np.array(train_data['t'])\n",
    "normalizer = layers.Normalization(input_shape=[1,], axis=None)\n",
    "normalizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=64, activation='relu'),\n",
    "    layers.Dense(units=64, activation='relu'),\n",
    "    layers.Dense(units = 1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,356</span> (17.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,356\u001b[0m (17.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,353</span> (17.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,353\u001b[0m (17.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (16.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3\u001b[0m (16.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_absolute_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 871us/step - loss: 1.6205 - val_loss: 1.1038\n",
      "Epoch 2/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 885us/step - loss: 1.1108 - val_loss: 1.1267\n",
      "Epoch 3/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 860us/step - loss: 1.1119 - val_loss: 1.1040\n",
      "Epoch 4/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 854us/step - loss: 1.1085 - val_loss: 1.1214\n",
      "Epoch 5/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 858us/step - loss: 1.1103 - val_loss: 1.1032\n",
      "Epoch 6/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 852us/step - loss: 1.1105 - val_loss: 1.1063\n",
      "Epoch 7/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 854us/step - loss: 1.1100 - val_loss: 1.1035\n",
      "Epoch 8/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 849us/step - loss: 1.1110 - val_loss: 1.1370\n",
      "Epoch 9/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 943us/step - loss: 1.1097 - val_loss: 1.1042\n",
      "Epoch 10/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 850us/step - loss: 1.1101 - val_loss: 1.1038\n",
      "Epoch 11/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 852us/step - loss: 1.1086 - val_loss: 1.1058\n",
      "Epoch 12/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 850us/step - loss: 1.1059 - val_loss: 1.1166\n",
      "Epoch 13/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 859us/step - loss: 1.1106 - val_loss: 1.1030\n",
      "Epoch 14/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - loss: 1.1096 - val_loss: 1.1035\n",
      "Epoch 15/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 848us/step - loss: 1.1100 - val_loss: 1.1070\n",
      "Epoch 16/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - loss: 1.1128 - val_loss: 1.1077\n",
      "Epoch 17/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 847us/step - loss: 1.1073 - val_loss: 1.1118\n",
      "Epoch 18/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 858us/step - loss: 1.1071 - val_loss: 1.1049\n",
      "Epoch 19/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - loss: 1.1087 - val_loss: 1.1048\n",
      "Epoch 20/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 872us/step - loss: 1.1073 - val_loss: 1.1033\n",
      "Epoch 21/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 874us/step - loss: 1.1084 - val_loss: 1.1035\n",
      "Epoch 22/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 862us/step - loss: 1.1049 - val_loss: 1.1211\n",
      "Epoch 23/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - loss: 1.1110 - val_loss: 1.1043\n",
      "Epoch 24/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 860us/step - loss: 1.1076 - val_loss: 1.1057\n",
      "Epoch 25/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 855us/step - loss: 1.1046 - val_loss: 1.1286\n",
      "Epoch 26/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 862us/step - loss: 1.1067 - val_loss: 1.1041\n",
      "Epoch 27/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 855us/step - loss: 1.1086 - val_loss: 1.1066\n",
      "Epoch 28/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - loss: 1.1086 - val_loss: 1.1045\n",
      "Epoch 29/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 853us/step - loss: 1.1062 - val_loss: 1.1053\n",
      "Epoch 30/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 859us/step - loss: 1.1098 - val_loss: 1.1051\n",
      "Epoch 31/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 930us/step - loss: 1.1071 - val_loss: 1.1064\n",
      "Epoch 32/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - loss: 1.1059 - val_loss: 1.1033\n",
      "Epoch 33/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 859us/step - loss: 1.1045 - val_loss: 1.1054\n",
      "Epoch 34/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 860us/step - loss: 1.1115 - val_loss: 1.1030\n",
      "Epoch 35/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 861us/step - loss: 1.1081 - val_loss: 1.1042\n",
      "Epoch 36/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 851us/step - loss: 1.1062 - val_loss: 1.1038\n",
      "Epoch 37/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 937us/step - loss: 1.1120 - val_loss: 1.1039\n",
      "Epoch 38/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 854us/step - loss: 1.1032 - val_loss: 1.1069\n",
      "Epoch 39/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 866us/step - loss: 1.1075 - val_loss: 1.1085\n",
      "Epoch 40/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 853us/step - loss: 1.1051 - val_loss: 1.1064\n",
      "Epoch 41/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 863us/step - loss: 1.1086 - val_loss: 1.1048\n",
      "Epoch 42/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 854us/step - loss: 1.1080 - val_loss: 1.1040\n",
      "Epoch 43/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 860us/step - loss: 1.1052 - val_loss: 1.1072\n",
      "Epoch 44/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - loss: 1.1094 - val_loss: 1.1051\n",
      "Epoch 45/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 857us/step - loss: 1.1052 - val_loss: 1.1056\n",
      "Epoch 46/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 855us/step - loss: 1.1037 - val_loss: 1.1136\n",
      "Epoch 47/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 862us/step - loss: 1.1035 - val_loss: 1.1040\n",
      "Epoch 48/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 855us/step - loss: 1.1035 - val_loss: 1.1039\n",
      "Epoch 49/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 862us/step - loss: 1.1030 - val_loss: 1.1031\n",
      "Epoch 50/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 853us/step - loss: 1.1090 - val_loss: 1.1090\n",
      "Epoch 51/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 866us/step - loss: 1.1076 - val_loss: 1.1051\n",
      "Epoch 52/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 853us/step - loss: 1.1096 - val_loss: 1.1049\n",
      "Epoch 53/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 862us/step - loss: 1.1050 - val_loss: 1.1034\n",
      "Epoch 54/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 871us/step - loss: 1.1077 - val_loss: 1.1029\n",
      "Epoch 55/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 880us/step - loss: 1.1077 - val_loss: 1.1030\n",
      "Epoch 56/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931us/step - loss: 1.1065 - val_loss: 1.1032\n",
      "Epoch 57/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 854us/step - loss: 1.1030 - val_loss: 1.1038\n",
      "Epoch 58/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 858us/step - loss: 1.1042 - val_loss: 1.1031\n",
      "Epoch 59/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925us/step - loss: 1.1058 - val_loss: 1.1029\n",
      "Epoch 60/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 865us/step - loss: 1.1054 - val_loss: 1.1054\n",
      "Epoch 61/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 859us/step - loss: 1.1062 - val_loss: 1.1042\n",
      "Epoch 62/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 861us/step - loss: 1.1073 - val_loss: 1.1063\n",
      "Epoch 63/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 857us/step - loss: 1.1059 - val_loss: 1.1038\n",
      "Epoch 64/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 860us/step - loss: 1.1100 - val_loss: 1.1034\n",
      "Epoch 65/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 853us/step - loss: 1.1056 - val_loss: 1.1080\n",
      "Epoch 66/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 858us/step - loss: 1.1063 - val_loss: 1.1075\n",
      "Epoch 67/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 852us/step - loss: 1.1045 - val_loss: 1.1167\n",
      "Epoch 68/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 861us/step - loss: 1.1045 - val_loss: 1.1069\n",
      "Epoch 69/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - loss: 1.1003 - val_loss: 1.1058\n",
      "Epoch 70/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 859us/step - loss: 1.1061 - val_loss: 1.1043\n",
      "Epoch 71/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 855us/step - loss: 1.1072 - val_loss: 1.1034\n",
      "Epoch 72/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 858us/step - loss: 1.1059 - val_loss: 1.1034\n",
      "Epoch 73/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 854us/step - loss: 1.1044 - val_loss: 1.1171\n",
      "Epoch 74/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 861us/step - loss: 1.1069 - val_loss: 1.1030\n",
      "Epoch 75/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 860us/step - loss: 1.1076 - val_loss: 1.1043\n",
      "Epoch 76/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 863us/step - loss: 1.1053 - val_loss: 1.1036\n",
      "Epoch 77/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 855us/step - loss: 1.1065 - val_loss: 1.1041\n",
      "Epoch 78/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 867us/step - loss: 1.1049 - val_loss: 1.1027\n",
      "Epoch 79/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 851us/step - loss: 1.1031 - val_loss: 1.1036\n",
      "Epoch 80/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 864us/step - loss: 1.1064 - val_loss: 1.1056\n",
      "Epoch 81/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - loss: 1.1034 - val_loss: 1.1052\n",
      "Epoch 82/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - loss: 1.1039 - val_loss: 1.1034\n",
      "Epoch 83/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 851us/step - loss: 1.1030 - val_loss: 1.1033\n",
      "Epoch 84/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 854us/step - loss: 1.1048 - val_loss: 1.1033\n",
      "Epoch 85/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 858us/step - loss: 1.1036 - val_loss: 1.1033\n",
      "Epoch 86/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 863us/step - loss: 1.1053 - val_loss: 1.1078\n",
      "Epoch 87/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 878us/step - loss: 1.1023 - val_loss: 1.1035\n",
      "Epoch 88/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 855us/step - loss: 1.1041 - val_loss: 1.1098\n",
      "Epoch 89/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 866us/step - loss: 1.1025 - val_loss: 1.1037\n",
      "Epoch 90/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 858us/step - loss: 1.1058 - val_loss: 1.1032\n",
      "Epoch 91/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 864us/step - loss: 1.1008 - val_loss: 1.1033\n",
      "Epoch 92/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 861us/step - loss: 1.1046 - val_loss: 1.1044\n",
      "Epoch 93/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 859us/step - loss: 1.1072 - val_loss: 1.1030\n",
      "Epoch 94/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 854us/step - loss: 1.1017 - val_loss: 1.1045\n",
      "Epoch 95/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 861us/step - loss: 1.1045 - val_loss: 1.1045\n",
      "Epoch 96/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 858us/step - loss: 1.1070 - val_loss: 1.1028\n",
      "Epoch 97/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 861us/step - loss: 1.1045 - val_loss: 1.1030\n",
      "Epoch 98/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 857us/step - loss: 1.1028 - val_loss: 1.1030\n",
      "Epoch 99/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 867us/step - loss: 1.1034 - val_loss: 1.1037\n",
      "Epoch 100/100\n",
      "\u001b[1m6087/6087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 858us/step - loss: 1.1072 - val_loss: 1.1038\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data['t'],\n",
    "    train_data['p'],\n",
    "    epochs=100,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/2536\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 38ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2536/2536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 603us/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_data['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.10\n",
      "Root Mean Squarred Error (RMSE): 1.46\n",
      "R2 Score 0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "\n",
    "print(\"Mean Absolute Error (MAE): %.2f\" % mean_absolute_error(test_data[['p']], prediction))\n",
    "print(\"Root Mean Squarred Error (RMSE): %.2f\" % root_mean_squared_error(test_data[['p']], prediction))\n",
    "print(\"R2 Score %.2f\" % r2_score(test_data[['p']], prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
